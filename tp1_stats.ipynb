{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a5c5d58",
   "metadata": {},
   "source": [
    "# TP1 : Algorithme EM et modèle de mélange gaussien\n",
    "\n",
    "## Introduction à l'estimation statistique - G3 SDIA\n",
    "\n",
    "L'objectif de ce TP est d'implémenter l'algorithme EM pour estimer par maximum de vraisemblance les paramètres d'un modèle de mélange gaussien.\n",
    "\n",
    "On utilisera le dataset *Old Faithful*, qui décrit 272 éruptions du geyser appelé Old Faithful du parc national de Yellowstone aux États-Unis. Chaque observation est constituée de 2 variables : le temps d'attente avant l'éruption (en minutes) et la durée de l'éruption (en minutes).\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Renommer votre notebook sous la forme `tp1_Nom1_Nom2.ipynb`, et inclure le nom du binôme dans le notebook. \n",
    "\n",
    "2. Votre code, ainsi que toute sortie du code, doivent être commentés !\n",
    "\n",
    "3. Déposer votre notebook sur Moodle dans la section prévue à cet effet avant la date limite : 15 Octobre 2023, 23h59."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31576d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import seaborn\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d78659",
   "metadata": {},
   "source": [
    "**Q1**. Charger le dataset, normaliser puis visualiser les données. Commenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87ffb7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.6   79.   ]\n",
      " [ 1.8   54.   ]\n",
      " [ 3.333 74.   ]\n",
      " [ 2.283 62.   ]\n",
      " [ 4.533 85.   ]\n",
      " [ 2.883 55.   ]\n",
      " [ 4.7   88.   ]\n",
      " [ 3.6   85.   ]\n",
      " [ 1.95  51.   ]\n",
      " [ 4.35  85.   ]\n",
      " [ 1.833 54.   ]\n",
      " [ 3.917 84.   ]\n",
      " [ 4.2   78.   ]\n",
      " [ 1.75  47.   ]\n",
      " [ 4.7   83.   ]\n",
      " [ 2.167 52.   ]\n",
      " [ 1.75  62.   ]\n",
      " [ 4.8   84.   ]\n",
      " [ 1.6   52.   ]\n",
      " [ 4.25  79.   ]\n",
      " [ 1.8   51.   ]\n",
      " [ 1.75  47.   ]\n",
      " [ 3.45  78.   ]\n",
      " [ 3.067 69.   ]\n",
      " [ 4.533 74.   ]\n",
      " [ 3.6   83.   ]\n",
      " [ 1.967 55.   ]\n",
      " [ 4.083 76.   ]\n",
      " [ 3.85  78.   ]\n",
      " [ 4.433 79.   ]\n",
      " [ 4.3   73.   ]\n",
      " [ 4.467 77.   ]\n",
      " [ 3.367 66.   ]\n",
      " [ 4.033 80.   ]\n",
      " [ 3.833 74.   ]\n",
      " [ 2.017 52.   ]\n",
      " [ 1.867 48.   ]\n",
      " [ 4.833 80.   ]\n",
      " [ 1.833 59.   ]\n",
      " [ 4.783 90.   ]\n",
      " [ 4.35  80.   ]\n",
      " [ 1.883 58.   ]\n",
      " [ 4.567 84.   ]\n",
      " [ 1.75  58.   ]\n",
      " [ 4.533 73.   ]\n",
      " [ 3.317 83.   ]\n",
      " [ 3.833 64.   ]\n",
      " [ 2.1   53.   ]\n",
      " [ 4.633 82.   ]\n",
      " [ 2.    59.   ]\n",
      " [ 4.8   75.   ]\n",
      " [ 4.716 90.   ]\n",
      " [ 1.833 54.   ]\n",
      " [ 4.833 80.   ]\n",
      " [ 1.733 54.   ]\n",
      " [ 4.883 83.   ]\n",
      " [ 3.717 71.   ]\n",
      " [ 1.667 64.   ]\n",
      " [ 4.567 77.   ]\n",
      " [ 4.317 81.   ]\n",
      " [ 2.233 59.   ]\n",
      " [ 4.5   84.   ]\n",
      " [ 1.75  48.   ]\n",
      " [ 4.8   82.   ]\n",
      " [ 1.817 60.   ]\n",
      " [ 4.4   92.   ]\n",
      " [ 4.167 78.   ]\n",
      " [ 4.7   78.   ]\n",
      " [ 2.067 65.   ]\n",
      " [ 4.7   73.   ]\n",
      " [ 4.033 82.   ]\n",
      " [ 1.967 56.   ]\n",
      " [ 4.5   79.   ]\n",
      " [ 4.    71.   ]\n",
      " [ 1.983 62.   ]\n",
      " [ 5.067 76.   ]\n",
      " [ 2.017 60.   ]\n",
      " [ 4.567 78.   ]\n",
      " [ 3.883 76.   ]\n",
      " [ 3.6   83.   ]\n",
      " [ 4.133 75.   ]\n",
      " [ 4.333 82.   ]\n",
      " [ 4.1   70.   ]\n",
      " [ 2.633 65.   ]\n",
      " [ 4.067 73.   ]\n",
      " [ 4.933 88.   ]\n",
      " [ 3.95  76.   ]\n",
      " [ 4.517 80.   ]\n",
      " [ 2.167 48.   ]\n",
      " [ 4.    86.   ]\n",
      " [ 2.2   60.   ]\n",
      " [ 4.333 90.   ]\n",
      " [ 1.867 50.   ]\n",
      " [ 4.817 78.   ]\n",
      " [ 1.833 63.   ]\n",
      " [ 4.3   72.   ]\n",
      " [ 4.667 84.   ]\n",
      " [ 3.75  75.   ]\n",
      " [ 1.867 51.   ]\n",
      " [ 4.9   82.   ]\n",
      " [ 2.483 62.   ]\n",
      " [ 4.367 88.   ]\n",
      " [ 2.1   49.   ]\n",
      " [ 4.5   83.   ]\n",
      " [ 4.05  81.   ]\n",
      " [ 1.867 47.   ]\n",
      " [ 4.7   84.   ]\n",
      " [ 1.783 52.   ]\n",
      " [ 4.85  86.   ]\n",
      " [ 3.683 81.   ]\n",
      " [ 4.733 75.   ]\n",
      " [ 2.3   59.   ]\n",
      " [ 4.9   89.   ]\n",
      " [ 4.417 79.   ]\n",
      " [ 1.7   59.   ]\n",
      " [ 4.633 81.   ]\n",
      " [ 2.317 50.   ]\n",
      " [ 4.6   85.   ]\n",
      " [ 1.817 59.   ]\n",
      " [ 4.417 87.   ]\n",
      " [ 2.617 53.   ]\n",
      " [ 4.067 69.   ]\n",
      " [ 4.25  77.   ]\n",
      " [ 1.967 56.   ]\n",
      " [ 4.6   88.   ]\n",
      " [ 3.767 81.   ]\n",
      " [ 1.917 45.   ]\n",
      " [ 4.5   82.   ]\n",
      " [ 2.267 55.   ]\n",
      " [ 4.65  90.   ]\n",
      " [ 1.867 45.   ]\n",
      " [ 4.167 83.   ]\n",
      " [ 2.8   56.   ]\n",
      " [ 4.333 89.   ]\n",
      " [ 1.833 46.   ]\n",
      " [ 4.383 82.   ]\n",
      " [ 1.883 51.   ]\n",
      " [ 4.933 86.   ]\n",
      " [ 2.033 53.   ]\n",
      " [ 3.733 79.   ]\n",
      " [ 4.233 81.   ]\n",
      " [ 2.233 60.   ]\n",
      " [ 4.533 82.   ]\n",
      " [ 4.817 77.   ]\n",
      " [ 4.333 76.   ]\n",
      " [ 1.983 59.   ]\n",
      " [ 4.633 80.   ]\n",
      " [ 2.017 49.   ]\n",
      " [ 5.1   96.   ]\n",
      " [ 1.8   53.   ]\n",
      " [ 5.033 77.   ]\n",
      " [ 4.    77.   ]\n",
      " [ 2.4   65.   ]\n",
      " [ 4.6   81.   ]\n",
      " [ 3.567 71.   ]\n",
      " [ 4.    70.   ]\n",
      " [ 4.5   81.   ]\n",
      " [ 4.083 93.   ]\n",
      " [ 1.8   53.   ]\n",
      " [ 3.967 89.   ]\n",
      " [ 2.2   45.   ]\n",
      " [ 4.15  86.   ]\n",
      " [ 2.    58.   ]\n",
      " [ 3.833 78.   ]\n",
      " [ 3.5   66.   ]\n",
      " [ 4.583 76.   ]\n",
      " [ 2.367 63.   ]\n",
      " [ 5.    88.   ]\n",
      " [ 1.933 52.   ]\n",
      " [ 4.617 93.   ]\n",
      " [ 1.917 49.   ]\n",
      " [ 2.083 57.   ]\n",
      " [ 4.583 77.   ]\n",
      " [ 3.333 68.   ]\n",
      " [ 4.167 81.   ]\n",
      " [ 4.333 81.   ]\n",
      " [ 4.5   73.   ]\n",
      " [ 2.417 50.   ]\n",
      " [ 4.    85.   ]\n",
      " [ 4.167 74.   ]\n",
      " [ 1.883 55.   ]\n",
      " [ 4.583 77.   ]\n",
      " [ 4.25  83.   ]\n",
      " [ 3.767 83.   ]\n",
      " [ 2.033 51.   ]\n",
      " [ 4.433 78.   ]\n",
      " [ 4.083 84.   ]\n",
      " [ 1.833 46.   ]\n",
      " [ 4.417 83.   ]\n",
      " [ 2.183 55.   ]\n",
      " [ 4.8   81.   ]\n",
      " [ 1.833 57.   ]\n",
      " [ 4.8   76.   ]\n",
      " [ 4.1   84.   ]\n",
      " [ 3.966 77.   ]\n",
      " [ 4.233 81.   ]\n",
      " [ 3.5   87.   ]\n",
      " [ 4.366 77.   ]\n",
      " [ 2.25  51.   ]\n",
      " [ 4.667 78.   ]\n",
      " [ 2.1   60.   ]\n",
      " [ 4.35  82.   ]\n",
      " [ 4.133 91.   ]\n",
      " [ 1.867 53.   ]\n",
      " [ 4.6   78.   ]\n",
      " [ 1.783 46.   ]\n",
      " [ 4.367 77.   ]\n",
      " [ 3.85  84.   ]\n",
      " [ 1.933 49.   ]\n",
      " [ 4.5   83.   ]\n",
      " [ 2.383 71.   ]\n",
      " [ 4.7   80.   ]\n",
      " [ 1.867 49.   ]\n",
      " [ 3.833 75.   ]\n",
      " [ 3.417 64.   ]\n",
      " [ 4.233 76.   ]\n",
      " [ 2.4   53.   ]\n",
      " [ 4.8   94.   ]\n",
      " [ 2.    55.   ]\n",
      " [ 4.15  76.   ]\n",
      " [ 1.867 50.   ]\n",
      " [ 4.267 82.   ]\n",
      " [ 1.75  54.   ]\n",
      " [ 4.483 75.   ]\n",
      " [ 4.    78.   ]\n",
      " [ 4.117 79.   ]\n",
      " [ 4.083 78.   ]\n",
      " [ 4.267 78.   ]\n",
      " [ 3.917 70.   ]\n",
      " [ 4.55  79.   ]\n",
      " [ 4.083 70.   ]\n",
      " [ 2.417 54.   ]\n",
      " [ 4.183 86.   ]\n",
      " [ 2.217 50.   ]\n",
      " [ 4.45  90.   ]\n",
      " [ 1.883 54.   ]\n",
      " [ 1.85  54.   ]\n",
      " [ 4.283 77.   ]\n",
      " [ 3.95  79.   ]\n",
      " [ 2.333 64.   ]\n",
      " [ 4.15  75.   ]\n",
      " [ 2.35  47.   ]\n",
      " [ 4.933 86.   ]\n",
      " [ 2.9   63.   ]\n",
      " [ 4.583 85.   ]\n",
      " [ 3.833 82.   ]\n",
      " [ 2.083 57.   ]\n",
      " [ 4.367 82.   ]\n",
      " [ 2.133 67.   ]\n",
      " [ 4.35  74.   ]\n",
      " [ 2.2   54.   ]\n",
      " [ 4.45  83.   ]\n",
      " [ 3.567 73.   ]\n",
      " [ 4.5   73.   ]\n",
      " [ 4.15  88.   ]\n",
      " [ 3.817 80.   ]\n",
      " [ 3.917 71.   ]\n",
      " [ 4.45  83.   ]\n",
      " [ 2.    56.   ]\n",
      " [ 4.283 79.   ]\n",
      " [ 4.767 78.   ]\n",
      " [ 4.533 84.   ]\n",
      " [ 1.85  58.   ]\n",
      " [ 4.25  83.   ]\n",
      " [ 1.983 43.   ]\n",
      " [ 2.25  60.   ]\n",
      " [ 4.75  75.   ]\n",
      " [ 4.117 81.   ]\n",
      " [ 2.15  46.   ]\n",
      " [ 4.417 90.   ]\n",
      " [ 1.817 46.   ]\n",
      " [ 4.467 74.   ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "\n",
    "# Téléchargez le fichier CSV manuellement depuis le lien Seaborn\n",
    "url = \"https://github.com/mwaskom/seaborn-data/raw/master/geyser.csv\"\n",
    "response = requests.get(url)\n",
    "data = io.StringIO(response.text)\n",
    "# Chargez les données à partir du fichier local\n",
    "df = pd.read_csv(data)\n",
    "\n",
    "X = df[['duration', 'waiting']].values\n",
    "N, D = X. shape\n",
    "\n",
    "# Standardize data to avoid numerical instabilities\n",
    "standardize = lambda vec : (vec - np.mean(vec))/np.std(vec)\n",
    "X = standardize(X)\n",
    "\n",
    "# Show data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef8799a",
   "metadata": {},
   "source": [
    "\n",
    "----- Votre réponse ici -----\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06528c4",
   "metadata": {},
   "source": [
    "**Q2**. On note $\\mathbf{x}_1,...,\\mathbf{x}_n$ les données. On souhaite les modéliser par un modèle de mélange gaussien à $K$ composantes.\n",
    "\n",
    "Écrire une fonction permettant de calculer la log-vraisemblance :\n",
    "$$ \\log \\mathcal{L}(\\theta;\\mathbf{x}_1,...,\\mathbf{x}_n) = \\sum_{i=1}^n \\log \\left( \\sum_{k=1}^K \\pi_k \\frac{1}{2 \\pi \\text{det}(\\boldsymbol{\\Sigma}_k)^{1/2}} \\exp \\left( \\frac{1}{2} (\\mathbf{x}_i - \\boldsymbol{\\mu}_k)^{\\top} \\boldsymbol{\\Sigma}_k^{-1} (\\mathbf{x}_i - \\boldsymbol{\\mu}_k) \\right) \\right), $$\n",
    "avec $\\theta = \\{ \\boldsymbol{\\mu_1}, ..., \\boldsymbol{\\mu_k}, \\boldsymbol{\\Sigma}_1, ..., \\boldsymbol{\\Sigma}_k, \\pi_1, ..., \\pi_k \\}$.\n",
    "\n",
    "On pourra utiliser la fonction $\\texttt{multivariate} \\_ \\texttt{normal.pdf}$ de la librairie scipy.stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6a3ffe5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (311551088.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Antonin MOREL\\AppData\\Local\\Temp\\ipykernel_11884\\311551088.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    # # # # # # # # #\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def log_likelihood(): # Fill in the appropriate arguments\n",
    "\n",
    "    # # # # # # # # #\n",
    "    # YOUR CODE HERE #\n",
    "    # # # # # # # # #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3bfc0f",
   "metadata": {},
   "source": [
    "**Q3**. Écrire une fonction qui implémente l'algorithme EM dans ce modèle, prenant pour arguments les données, le nombre de composantes $K$, et le nombre d'itérations de l'algorithme $N_{\\text{iter}}$. Cette fonction retournera un tableau de taille $N_{\\text{iter}} + 1$ contenant l'évolution des valeurs de la log-vraisemblance, ainsi que les valeurs finales des paramètres.\n",
    "\n",
    "Initialisation des paramètres :\n",
    "- Pour les moyennes, les $K$ premières observations du dataset ;\n",
    "- Pour les matrices de covariances, la matrice identité ;\n",
    "- $\\pi_k = 1/K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc3afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM_algorithm_v1(X, K, Niter):\n",
    "    N, D = X. shape\n",
    "    \n",
    "    # Initialize parameters\n",
    "\n",
    "    # # # # # # # # #\n",
    "    # YOUR CODE HERE #\n",
    "    # # # # # # # # #\n",
    "\n",
    "    for i in range(0,Niter):\n",
    "        # E-STEP\n",
    "        \n",
    "        # # # # # # # # #\n",
    "        # YOUR CODE HERE #\n",
    "        # # # # # # # # #\n",
    "        \n",
    "        # M-STEP\n",
    "        \n",
    "        # # # # # # # # #\n",
    "        # YOUR CODE HERE #\n",
    "        # # # # # # # # #\n",
    "        \n",
    "    return # YOUR CODE HERE #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f096d0d",
   "metadata": {},
   "source": [
    "**Q4**. Faire tourner l'algorithme avec $K = 2$ et $N_{\\text{iter}} = 50$.\n",
    "\n",
    "Afficher l'évolution de la log-vraisemblance en fonction des itérations. Commenter.\n",
    "\n",
    "Sur une même figure, afficher le dataset et représenter les estimations des deux lois normales du mélange à l'aide d'un *contour plot*. On pourra utiliser la fonction $\\texttt{plt.contour}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05c1379",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2\n",
    "Niter = 50\n",
    "\n",
    "# # # # # # # # #\n",
    "# YOUR CODE HERE #\n",
    "# # # # # # # # #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374ee4cb",
   "metadata": {},
   "source": [
    "----- Votre réponse ici -----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e57e26",
   "metadata": {},
   "source": [
    "**Q5**. On souhaite maintenant étudier l'influence de l'initialisation sur les résultats. Modifier la fonction implémentant l'algorithme EM en y rajoutant un argument pour la graine aléatoire. Les paramètres seront maintenant initialisés de la manière suivante :\n",
    "- $\\boldsymbol{\\mu}_k \\sim \\mathcal{N}(\\mathbf{0},\\mathbf{I}_2)$ ;\n",
    "- $[\\pi_1, ..., \\pi_K]^{\\top} \\sim \\text{Dirichlet}([1, ..., 1]^{\\top})$ ;\n",
    "- On gardera l'initialisation des matrices de covariance à la matrice identité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58600cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM_algorithm_v2(X, K, Niter, seed):\n",
    "    N, D = X. shape\n",
    "    \n",
    "    # Initialize parameters\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # # # # # # # # #\n",
    "    # YOUR CODE HERE #\n",
    "    # # # # # # # # #\n",
    "\n",
    "    for i in range(0,Niter):\n",
    "        # E-STEP\n",
    "        \n",
    "        # # # # # # # # #\n",
    "        # YOUR CODE HERE #\n",
    "        # # # # # # # # #\n",
    "        \n",
    "        # M-STEP\n",
    "        \n",
    "        # # # # # # # # #\n",
    "        # YOUR CODE HERE #\n",
    "        # # # # # # # # #\n",
    "        \n",
    "    return # YOUR CODE HERE #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae230134",
   "metadata": {},
   "source": [
    "**Q6**. On choisit maintenant $K=3$. Représenter l'évolution de la log-vraisemblance pour 10 graines aléatoires différentes. Commenter.\n",
    "\n",
    "Afficher deux cas où la solution retournée par l'algorithme EM est visuellement différente. Commenter.\n",
    "\n",
    "Quelle estimation de paramètres doit-on choisir ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7467b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "\n",
    "# # # # # # # # #\n",
    "# YOUR CODE HERE #\n",
    "# # # # # # # # #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0002c3",
   "metadata": {},
   "source": [
    "\n",
    "----- Votre réponse ici -----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a74d13",
   "metadata": {},
   "source": [
    "**Q7**. On cherche maintenant à choisir la valeur optimale de $K$. Pour cela, on aimerait pouvoir comparer la vraisemblance des modèles obtenus avec différentes valeurs de $K$.\n",
    "\n",
    "Cela peut se faire au travers d'un critère de sélection de modèle. Dans ce TP, nous étudierons le critère dit BIC :\n",
    "$$ \\text{BIC}(m) = k(m) \\log(n) - 2 \\log \\mathcal{L}(m),$$\n",
    "où $m$ est un modèle (ici donné par une valeur de $K$), $k_m$ est le nombre de paramètres libres dans le modèle, $n$ le nombre d'échantillons, et $\\mathcal{L}_m$ le maximum de la fonction de vraisemblance de le modèle $m$. On sélectionne le modèle avec le plus faible BIC.\n",
    "\n",
    "Montrer que $$k(m) = \\frac{K}{2} (D+1)(D+2) - 1.$$\n",
    "\n",
    "Comparer les valeurs de $K$ allant de 1 à 6. Quel est le modèle optimal d'après le critère BIC ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ed453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # # # # #\n",
    "# YOUR CODE HERE #\n",
    "# # # # # # # # #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e689fe03",
   "metadata": {},
   "source": [
    "\n",
    "----- Votre réponse ici -----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd103c6",
   "metadata": {},
   "source": [
    "**Question bonus**. Expliquer comment l'algorithme EM peut-être utilisé pour du clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8a1b08",
   "metadata": {},
   "source": [
    "\n",
    "----- Votre réponse ici -----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
